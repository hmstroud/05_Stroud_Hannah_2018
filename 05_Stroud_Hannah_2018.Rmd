---
title: "05_Stroud_Hannah_2018"
author: "Hannah Stroud"
date: "October 9, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## T test and Chisq

```{r}
library(readr)
library(dplyr)
library(ggplot2)
library(tidyr)
library(patchwork)
```
### 1 W&S X^2 Questions 
Ch 8: 12 & 24, Ch 9: 16 & 27  

####1.1 Ch8, Q12
87 bears sampled, 42-BB, 24-Bb, 21-bb  

12a. fraction of b alleles in population:  
P[b]-> 24+42)/(87*2)= 0.3793  

12b. expected_frequency of bionomial distribution
#Bb -> P[B]*P[b] -> (0.3793)* (1-0.3793)*2= 0.470863 
#bb -> P[b]*P[b] -> 
#BB -> P[B]*P[B] -> 
Expected frequency of Bb: 0.470863*87= 40.965 
Expected frequency of bb:(0.3793)^2= 0.1438*87= 12.5106
Expected frequency of BB: (1-0.3793)^2= 0.3852*87= 33.5183

12c. compare observed vs expected via graph
```{r}
observed<- c(42, 24, 21)
#in order BB, Bb, bb
expected<- c(33.5183, 40.965, 12.5106)

table= rbind(observed, expected)
colnames(table)= c("BB","Bb", "bb")
barplot(table, beside= TRUE, legend.text = c("observed","expected"))
```
The observed data doesn't match the expected. For BB and bb, the obeserved was greater than expected, and for Bb, the observed was less than expected. 

####1.2 Ch8, Q24
30 tested, 17 towards volatiles, 2 away, 7 to left, 4 to right  

24a. Graph the relative frequency distribution for these results. What type of graph is ideal?  
```{r}
Dodder <- read_csv("./Data/chap08q24DodderGrowth.csv")
Dodder <- Dodder %>% 
  group_by(directionOfGrowth) %>%
  tally()%>%
  mutate(rel_freq= n/30)

ggplot(data=Dodder, mapping= aes(x=directionOfGrowth, y=rel_freq, 
                                 fill= directionOfGrowth))+
  geom_col()
  

```
A bar graph is ideal because the data is discrete. 

24b. What is the relative expected frequency if the parasite is unable to detect volatiles/cues? add to graph in part a.  
```{r}
Dodder <- Dodder %>% 
  mutate(expected_no_cues= c(0.25,0.25,0.25,0.25))
ggplot(data=Dodder, mapping= aes(x=directionOfGrowth, y=rel_freq, 
                                 fill= directionOfGrowth))+
  geom_col()+
  geom_hline(yintercept = 0.25, color= "darkred") 
```
the red line represents the expected frequency if the plant didn't respond to volatile or any other cues present.  

24c. Using the data, calculate the fraction of seedlings growing towards volatiles
17/30= 0.567
This fraction estimates the likelihood within the sample of a seedling to grow towards the volatiles.  

24d. Provide a standard error for your estimate. What does the standard error represent?   
```{r}
p <- 17/30
sqrt((p*(1-p))/30)  #probability of something happening, multiplied by the probality of it not happening divided by the sample size
```
The standard error with this data tells us we have a fairly precise estimate of plants growing towards the volatiles.  

24e. Calculate the range of most-plausible values for the fraction of dodder seedlings that grow toward volatiles under experimental conditions. Does it include the fraction expected if the parasite is unable to detect plant volatiles or other cues?

CI from book: 2*SE 
```{r}
CI <-2*0.09047201
Upper_CI <- p + 2*CI
Lower_CI <- p - 2*CI
```
The range of most plausible values is 0.2047786 - 0.9285547. It does include the fraction.  
####1.3 Ch9 16

9a. Calculate the expected frequencies for a contingency test 

Expected Frequency (from book) = Row_total * Column_total/ Grand_total

```{r}
#prairie<- read_csv("./Data/chap09q16PrairieDogMultipleMating.csv")
mating_1_birth <- (249*87)/263
  mating_1_birth
mating_2_birth <- (249*93)/263
  mating_2_birth
mating_3_birth <- (249*61)/263
  mating_3_birth
mating_4_birth <- (249*17)/263
  mating_4_birth
mating_5_birth <- (249*5)/263
  mating_5_birth
mating_1_no_b <- (14*87)/263
  mating_1_no_b
mating_2_no_b <- (14*93)/263
  mating_2_no_b
mating_3_no_b <- (14*61)/263
  mating_3_no_b
mating_4_no_b <- (14*17)/263
  mating_4_no_b
mating_5_no_b <- (14*5)/263
  mating_5_no_b
```
9b. They don't meet the assumptions, we have two expected frequencies less than 1. The categories could be combined to get larger frequencies (ie mates 2 times or less, mates 3 times of more), or a permutation test could be done instead of a chi squared.  

9c. It is likely that mating with more males increases the probability of giving birth, but there could also be a relationship between something else (hormones, health, etc) of prairie dogs that increases their chances of giving birth, and their tendency to mate more often.  

####1.4 Ch9 27
132 test group                         98 control
28 marked deterioration                7 marked deterioration
47 moderate deterioration              31 moderate
57 no deterioration                    60 none 


```{r}
widows <- read.csv("./data/chap09q27WidowHealth.csv") 
summary(widows)

table_w <- table(widows$health_deterioration, widows$widowed)
table_w

#test is whether the pattern of health deterioration was different between two groups

chisq.test(widows$health_deterioration,widows$widowed)
#Give P value as precisely as possible and interpret results
```
P= 0.00374, which is really low meaning we can reject the null that the two groups have the same pattern of health deterioration. 
### 2. W&S t-test Questions
Ch 11: 21, Ch 12: 20, 26, & 30
#### 2.1 Ch11 Q21

21a. graph the data
```{r}
soil <-read_csv("./data/chap11q21SoilLeadAndHurricanes.csv")
#given log ratios
#these log ratios have a normal distribution. 
ggplot(data=soil, mapping= aes(x= Site, y= Change)) +
  geom_col()

```
21b. Determine the most plausible range of values for mean change in soil (ie CI?). Describe in words the nature of the change. Is an increase consistent with the data? A decrease?
```{r}
library(broom)
tidy(t.test(soil$Change))
```
The most plausible range of mean change is between -201.4698 and -48.31283 mg/kg. An increase is not consistent with the data, most saw a decrease, hence the negative range of mean values. 

21c. Test whether mean soil lead changed after the hurricanes. 

```{R}
before <- mean(soil$Soil_lead_Before_Katrina)
before
after <- mean(soil$Soil_lead_After_Katrina)
after
```
The mean soil changed after hurricanes. 
#### 2.2 Ch12, Q20
20a. What is the difference between areas upstream and downstream? what is the 95% CI of the mean difference?  
```{r}
species<- read_csv("./data/chap12q20ElectricFish.csv")

species<- species %>% 
  mutate(differnce= speciesUpstream-speciesDownstream)
#check assumptions 
qqnorm(species$differnce) 

#one sample t-test 
 t.test(species$differnce,
                       unequal.var= TRUE)

```
The mean difference between upstream and downstream is -1.84. The confidence interval is -3.9464 to 0.2797  

20b. Test the hypothesis that the tributaries have no effect on number of species.
So the null hypothesis would be that the difference is 0, using the t test from above we find that our p value is 0.08, and we fail to reject the null. 
#### 2.3 Ch12, Q26
```{r}
hyenas <- read_csv("./data/chap12q26HyenaGiggles.csv")
#do dominant and subordinate differ? --> paired t-test
t.test(hyenas$dominantIndividualGiggleVariation, y=hyenas$subordinateIndividualGiggleVariation, paired= TRUE)
```
Our p value is just over 0.02157, we can reject the null- the means innn giggle spectral CV differ significantly. 

#### 2.4 Ch12, Q30 
They should not have used a two sample test because that looks at the difference between the two means. But you are looking at two populations, independent of each other in determining kin. You could evaluate them each separately to a null hypothesis. 

### 3. T and Power

#### 3.1 Data generating process 
Write a function that takes two means, two standard deviations, and two sample sizes as arguments. Have it return a data frame or tibble based on the inputs ready to go for a t-test!  

```{r} 
make_t_data <- function(m1, m2, s1, s2, n1, n2){
  #make a data frame, repeating treatments n number of times
  #and use rnorm to get values
  data.frame(treatment = c(rep("A", n1), rep("B", n2)),
             value = rnorm(n1+n2, mean = c(rep(m1,n1), rep(m2, n2)), sd= c(rep(s1,n1), rep(s2, n2))))
}

#check
make_t_data(m1=5, m2=8, s1=1, s2=2, n1=10, n2=15)
``` 

#### 3.2 P from T
Write a function that takes a data frame and runs a two-tailed t-test with the variances assumed to be unequal. Show it works by comparing itâ€™s p-value to that returned by t-test for the same simulated data set. Note, if you gave particular column names in the function from 3.1, you should use those here! If you are stumped on how to get a p-value, look at the help file for t.test, remembering that the output from t.test is a list! +2 Extra credit, look at ?ifelse or ?"if" and use one of them to have your function choose to use unequal variances if your variances differ by 20%.

```{r}
#fit a model with that data and get p?
#two-tailed test- I think that's the default....
get_p_from_t_test <- function(sim_data){
  test <- t.test(value ~ treatment, data = sim_data)
  test$p.value
}

#test out function 
#test out function above 
get_p_from_t_test(make_t_data(m1=5, m2=8, s1=1, s2=2, n1=10, n2=15))
#this is a very small value of p

```

#### 3.3 Generate many P's
Write a function that takes takes some number of simulations, two means, two standard deviations, and two sample sizes as arguments and returns a vector of p values equal in length to that number of simulations. It should call your functions from 3.1 and 3.2 using replicate() or  purrr::rerun() or some other strategy to do something many times. Your call! **Extra credit - try it different ways and show using a large number of simulations and system.time() or the profileR package which way is faster.

```{r}
#want a vector of p values of the length of number of simulations. 
gen_many_p <- function(nsim, m1, m2, s1, s2, n1, n2){
replicate(nsim,
          get_p_from_t_test(make_t_data(m1, m2, s1, s2, n1, n2)))
}

test <-gen_many_p(nsim=20,m1=5, m2=8, s1=1, s2=2, n1=10, n2=15)

```


#### 3.4 Power analysis
Write a function that takes an alpha value, some number of simulations, two means, two standard deviations, and two sample sizes as argument, and returns the power. It should call the function you wrote in 3.3. Now, make sure this works by comparing your results to the appropriate call to  power.t.test(). Do they agree? Why or why not?


```{r}
get_t_power <- function(m1, m2, s1,s2, n1,n2, nsim = 100, alpha = 0.05){
  #first, p values vector
  p <- gen_many_p(nsim, m1, m2, s1, s2, n1, n2)
  
  #number of incorrect p values 
  num_wrong <- sum(p > alpha)
  
  #equation for calculating power 
  1 - num_wrong/nsim
}

get_t_power(m1=5, m2=7, s1=1, s2=3, n1=10, n2=15)
```
You can't compare to a power.t.test because it doesn't work with a  difference in standard deviation. 

#### 3.5 Show it works 
Using your functions from above, explore how changing the difference between the the means of two groups interacts with the difference between two standard deviations of groups to affect the power of a t-test. Explain the results you produce. +1 Extra credit for using a color scheme from the wesanderson or beyonce package that is illuminating.

```{r}
#create data frame for various mean differences, sd differences
#keep n's constant 
pow_df <- crossing(diff_m = 1:4, diff_s = 1:4, n1= 10, n2=15) %>%
  rowwise() %>%
  mutate(power = get_t_power(m1 = 0, m2 = diff_m, s1=0, s2=diff_s, n1 = n1, n2= n2, nsim=100, alpha=0.05)) %>%
  ungroup()

#visualize differences 
library(beyonce)
power_uneq_var<- ggplot(data= pow_df, mapping= aes(x= diff_m, y= power, color= factor(diff_s)))+
         geom_point()+
         geom_line()+
    scale_color_manual(values = beyonce_palette(97, n=4, type= "continuous"))
power_uneq_var

```
Results show that as the difference between standard deviation increases, the power decreases. However as the difference between means increases, the power increases. The larger the difference between means, the more it will make up for a larger difference in standard deviation.  
A larger difference between the mean, it will be easier to see if there is a differnce between two treatments

#### 3.6 Extra Credit 
+2 Extra credit if you include a comparison between running the test with versus without equal variances - this might require you to re-write your function from 3.2 to include an argument where you specify if you want equal or unequal variance tests to be used. +1 additional extra credit for folding this into your auto-detect unequal variance function from above, but have this argument override the automatic detection of equal or unequal variances. Lots of ways to do this, some more efficient than others.

```{r}
#rewrite equation from 3.2
p_from_t_eq_var <- function(sim_data){
  test <- t.test(value ~ treatment, data = sim_data, var.equal= TRUE)
  test$p.value
}

get_t_power_var <- function(m1, m2, s1,s2, n1,n2, nsim = 50, alpha = 0.05){
  #first, p values vector
  p <- replicate(nsim,
                 p_from_t_eq_var(make_t_data(m1, m2, s1,s2, n1, n2)))
  
  #number of incorrect p values 
  num_wrong <- sum(p > alpha)
  
  #equation for calculating power 
  1 - num_wrong/nsim
}

get_t_power_var(m1=5, m2=7, s1=1, s2=3, n1=10, n2=15)
```
We have a lower power when running the test with equal variance. 

```{r}
pow_df_eq_var <- crossing(diff_m = 1:4, diff_s = 1:4, n1= 10, n2=15) %>%
  rowwise() %>%
  mutate(power = get_t_power(m1 = 0, m2 = diff_m, s1=0, s2=diff_s, n1 = n1, n2= n2, nsim=100, alpha=0.05)) %>%
  ungroup()

#visualize differences 
library(beyonce)
power_eq_var<- ggplot(data= pow_df, mapping= aes(x= diff_m, y= power, color= factor(diff_s)))+
         geom_point()+
         geom_line()+
    scale_color_manual(values = beyonce_palette(96, n=5, type= "continuous"))

power_eq_var+power_uneq_var
```
